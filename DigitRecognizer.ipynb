{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz237dlRExgF",
        "outputId": "d1b28979-8d37-4fbb-e256-927a9f84e462"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\read_weights.py:28: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
            "  np.uint8, np.uint16, np.object, np.bool]\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\yanni\\IA_IPSSI\\backend\\DigitRecognizer_pynb.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/IA_IPSSI/backend/DigitRecognizer_pynb.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/IA_IPSSI/backend/DigitRecognizer_pynb.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/yanni/IA_IPSSI/backend/DigitRecognizer_pynb.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfjs\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yanni/IA_IPSSI/backend/DigitRecognizer_pynb.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpymongo\u001b[39;00m \u001b[39mimport\u001b[39;00m MongoClient\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yanni/IA_IPSSI/backend/DigitRecognizer_pynb.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardScaler\n",
            "File \u001b[1;32mc:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m converters\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n",
            "File \u001b[1;32mc:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[39m# pylint: disable=unused-imports,line-too-long\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverter\u001b[39;00m \u001b[39mimport\u001b[39;00m convert\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_h5_conversion\u001b[39;00m \u001b[39mimport\u001b[39;00m save_keras_model\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras_tfjs_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m deserialize_keras_model\n",
            "File \u001b[1;32mc:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\converter.py:35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m version\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[1;32m---> 35\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_h5_conversion \u001b[39mas\u001b[39;00m conversion\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_tfjs_loader\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m tf_saved_model_conversion_v2\n",
            "File \u001b[1;32mc:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\converters\\keras_h5_conversion.py:33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m write_weights  \u001b[39m# pylint: disable=import-error\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconverters\u001b[39;00m \u001b[39mimport\u001b[39;00m common\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnormalize_weight_name\u001b[39m(weight_name):\n",
            "File \u001b[1;32mc:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\write_weights.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m read_weights\n\u001b[0;32m     27\u001b[0m _OUTPUT_DTYPES \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat16, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mint32, np\u001b[39m.\u001b[39mcomplex64,\n\u001b[0;32m     28\u001b[0m                   np\u001b[39m.\u001b[39muint8, np\u001b[39m.\u001b[39muint16, np\u001b[39m.\u001b[39mbool, np\u001b[39m.\u001b[39mobject]\n\u001b[0;32m     29\u001b[0m _AUTO_DTYPE_CONVERSION \u001b[39m=\u001b[39m {\n\u001b[0;32m     30\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat16): np\u001b[39m.\u001b[39mfloat32,\n\u001b[0;32m     31\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mfloat64): np\u001b[39m.\u001b[39mfloat32,\n\u001b[0;32m     32\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mint64): np\u001b[39m.\u001b[39mint32,\n\u001b[0;32m     33\u001b[0m     np\u001b[39m.\u001b[39mdtype(np\u001b[39m.\u001b[39mcomplex128): np\u001b[39m.\u001b[39mcomplex64}\n",
            "File \u001b[1;32mc:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflowjs\\read_weights.py:28\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflowjs\u001b[39;00m \u001b[39mimport\u001b[39;00m quantization\n\u001b[0;32m     27\u001b[0m _INPUT_DTYPES \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloat16, np\u001b[39m.\u001b[39mfloat32, np\u001b[39m.\u001b[39mint32, np\u001b[39m.\u001b[39mcomplex64,\n\u001b[1;32m---> 28\u001b[0m                  np\u001b[39m.\u001b[39muint8, np\u001b[39m.\u001b[39muint16, np\u001b[39m.\u001b[39;49mobject, np\u001b[39m.\u001b[39mbool]\n\u001b[0;32m     30\u001b[0m \u001b[39m# Number of bytes used to encode the length of a string in a string tensor.\u001b[39;00m\n\u001b[0;32m     31\u001b[0m STRING_LENGTH_NUM_BYTES \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\yanni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtesting\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'object'.\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
          ]
        }
      ],
      "source": [
        "#Import de Tensor et vérification de la version\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from pymongo import MongoClient\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "tdMQXKYeJjQZ",
        "outputId": "48ae26ae-de10-4028-b34c-747acd76dd44"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Connexion à la base de données MongoDB\n",
        "client = MongoClient(\"mongodb://localhost:27017\")\n",
        "db = client[\"DigitRecognizer\"]\n",
        "train_collection_name = \"train\"\n",
        "test_collection_name = \"test\"\n",
        "\n",
        "# Récupération des données d'entraînement et de test\n",
        "train_cursor = db[train_collection_name].find()\n",
        "test_cursor = db[test_collection_name].find()\n",
        "\n",
        "# Conversion des données en DataFrames pandas\n",
        "train_data = pd.DataFrame(list(train_cursor), columns=[\"label\"] + [f\"pixel{i}\" for i in range(784)])\n",
        "\n",
        "test_data = pd.DataFrame(list(test_cursor), columns=[f\"pixel{i}\" for i in range(784)])\n",
        "\n",
        "#Ferme la connexion à Mongo\n",
        "client.close()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1050/1050 [==============================] - 4s 3ms/step - loss: 0.2854 - accuracy: 0.9207 - val_loss: 0.2058 - val_accuracy: 0.9479\n",
            "Epoch 2/10\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.1135 - accuracy: 0.9662 - val_loss: 0.1969 - val_accuracy: 0.9564\n",
            "Epoch 3/10\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0686 - accuracy: 0.9789 - val_loss: 0.2046 - val_accuracy: 0.9604\n",
            "Epoch 4/10\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0507 - accuracy: 0.9844 - val_loss: 0.1975 - val_accuracy: 0.9618\n",
            "Epoch 5/10\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0370 - accuracy: 0.9884 - val_loss: 0.2436 - val_accuracy: 0.9611\n",
            "Epoch 6/10\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0257 - accuracy: 0.9924 - val_loss: 0.1826 - val_accuracy: 0.9633\n",
            "Epoch 7/10\n",
            "1050/1050 [==============================] - 4s 4ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.2076 - val_accuracy: 0.9632\n",
            "Epoch 8/10\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 0.2259 - val_accuracy: 0.9645\n",
            "Epoch 9/10\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0201 - accuracy: 0.9941 - val_loss: 0.2713 - val_accuracy: 0.9618\n",
            "Epoch 10/10\n",
            "1050/1050 [==============================] - 3s 3ms/step - loss: 0.0162 - accuracy: 0.9947 - val_loss: 0.2307 - val_accuracy: 0.9626\n",
            "263/263 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.9626\n",
            "Précision du modèle : 0.9626190662384033\n"
          ]
        }
      ],
      "source": [
        "# Diviser les données en features (X) et labels (y)\n",
        "X = train_data.drop(\"label\", axis=1)\n",
        "y = train_data[\"label\"]\n",
        "\n",
        "# Diviser les données en ensembles d'entraînement et de test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convertir les séries pandas en tableaux NumPy\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "\n",
        "# Normaliser les données\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Initialiser le modèle\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(784,)),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compiler le modèle avec l'optimiseur Adam\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entraîner le modèle\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Évaluer le modèle sur l'ensemble de test\n",
        "accuracy = model.evaluate(X_test, y_test)[1]\n",
        "print(f\"Précision du modèle : {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\",\"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
